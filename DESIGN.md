# 设计文档

## 架构概览
- 前端：静态站点，负责关卡选择、聊天交互、进度与成就展示。
- 后端：FastAPI 提供 `/api`，负责模型代理、攻击检测与 Flag 管理。
- 网关：nginx 反向代理将 `/api` 路由到后端，统一域名与安全边界。

## 前端
- 保持既有 UI 与交互逻辑，不在浏览器暴露任何密钥或 Flag。
- 通过 `POST /api/process` 与后端交互，接收 `aiResponse`、`systemResponse`、`flag`。
- 本地存储用户进度与已获取的 Flag，用于成就与展示。

## 后端
- `POST /api/process`：输入 `levelId` 与 `message`，输出 AI 响应与安全判定结果。
- 模型调用：在存在环境变量时调用模型 API，否则返回降级响应。
- 攻击检测：根据关卡实现模式识别，命中时安全发放对应 Flag。
- 管理安全词：通过环境变量控制，仅后端识别与发放。

## 安全设计
- 秘钥与配置：通过环境变量管理，避免在前端或仓库明文出现。
- Flag 存储：仅后端持有，不在前端代码与静态资源中出现。
- 反向代理：统一域名与路径，减少 CORS 问题与后端暴露面。
- 日志与隐私：后端不记录敏感密钥，错误信息最小化。

## 数据流
- 用户在前端输入消息与关卡。
- 前端调用 `/api/process`，后端进行检测与模型对话。
- 后端返回普通 AI 回复与系统判定消息，如命中则携带 Flag。
- 前端更新 UI、记录进度并展示 Flag。

## 部署
- `docker-compose` 编排：`frontend`(nginx) 与 `backend`(FastAPI)。
- `default.conf` 将 `/api` 代理到 `backend:8000/api/`。
- `.env` 管理密钥与配置。

## 风险与缓解
- 外部模型不可用：后端降级返回说明性响应，前端功能不受阻塞。
- 过度信任前端：攻击检测与 Flag 发放仅在后端执行。
- 密钥泄露：严禁在仓库与前端放置密钥，通过环境变量加载。

## 可扩展性
- 关卡与检测逻辑可在后端模块化扩展。
- 前端 UI 基本保持不变，易于迭代动画与交互。
- 可增加鉴权与会话管理以适应更复杂场景。
